{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o7aqNDTsmzOu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from pprint import pprint\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgrXGd5QRwGY",
        "outputId": "63164306-6d3e-4a91-ee7c-fd1866d5e2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.32.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (5.2.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (1.7.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (1.24.3)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (2.1.0)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (10.0.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (15.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (2.28.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (13.4.2)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (4.8.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (3.1.42)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\n",
            "Requirement already satisfied: toolz in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from click<9,>=7.0->streamlit) (0.4.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rahul\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# To create streamlit application\n",
        "!pip install streamlit\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "CVmYopsfmzOv"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx3gFKJ3mzOv",
        "outputId": "a658646b-f9b5-44a2-a066-6824a2c9f594"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fms9-rpgOeZq",
        "outputId": "77a04af3-8679-4b0a-bb85-4b17ca8768ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "#Download Shakespeare.txt file\n",
        "\n",
        "url = \"https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt\"\n",
        "file_path = \"shakespeare.txt\"\n",
        "\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(file_path, \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(\"File downloaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to download the file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nOnPvgsimzOw"
      },
      "outputs": [],
      "source": [
        "with open(\"shakespeare.txt\", \"r\") as file:\n",
        "    content = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT7-3FBVmzOw",
        "outputId": "ea256f2a-2abf-412a-fbfe-7590fce36551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '\\n',\n",
            " 1: ' ',\n",
            " 2: '!',\n",
            " 3: \"'\",\n",
            " 4: ',',\n",
            " 5: '-',\n",
            " 6: '.',\n",
            " 7: ':',\n",
            " 8: ';',\n",
            " 9: '?',\n",
            " 10: 'A',\n",
            " 11: 'B',\n",
            " 12: 'C',\n",
            " 13: 'D',\n",
            " 14: 'E',\n",
            " 15: 'F',\n",
            " 16: 'G',\n",
            " 17: 'H',\n",
            " 18: 'I',\n",
            " 19: 'J',\n",
            " 20: 'K',\n",
            " 21: 'L',\n",
            " 22: 'M',\n",
            " 23: 'N',\n",
            " 24: 'O',\n",
            " 25: 'P',\n",
            " 26: 'Q',\n",
            " 27: 'R',\n",
            " 28: 'S',\n",
            " 29: 'T',\n",
            " 30: 'U',\n",
            " 31: 'V',\n",
            " 32: 'W',\n",
            " 33: 'X',\n",
            " 34: 'Y',\n",
            " 35: 'Z',\n",
            " 36: 'a',\n",
            " 37: 'b',\n",
            " 38: 'c',\n",
            " 39: 'd',\n",
            " 40: 'e',\n",
            " 41: 'f',\n",
            " 42: 'g',\n",
            " 43: 'h',\n",
            " 44: 'i',\n",
            " 45: 'j',\n",
            " 46: 'k',\n",
            " 47: 'l',\n",
            " 48: 'm',\n",
            " 49: 'n',\n",
            " 50: 'o',\n",
            " 51: 'p',\n",
            " 52: 'q',\n",
            " 53: 'r',\n",
            " 54: 's',\n",
            " 55: 't',\n",
            " 56: 'u',\n",
            " 57: 'v',\n",
            " 58: 'w',\n",
            " 59: 'x',\n",
            " 60: 'y',\n",
            " 61: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(content)))\n",
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "# stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "pprint(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Wtto0O9KmzOw"
      },
      "outputs": [],
      "source": [
        "block_size = 20 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "\n",
        "\n",
        "#print(w)\n",
        "context = [1] * block_size\n",
        "for ch in content:\n",
        "  ix = stoi[ch]\n",
        "  X.append(context)\n",
        "  Y.append(ix)\n",
        "  # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "  context = context[1:] + [ix] # crop and append\n",
        "\n",
        "# Move data to GPU\n",
        "\n",
        "X = torch.tensor(X).to(device)\n",
        "Y = torch.tensor(Y).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u6vGmcomzOw",
        "outputId": "940dd08f-5de9-4132-f4d4-96211b02c3b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([99993, 20]), torch.int64, torch.Size([99993]), torch.int64)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKaBkRYNmzOw",
        "outputId": "712da61e-a905-493d-e4f3-ffd881ee532d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([62, 8])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_dim = 8\n",
        "emb = torch.nn.Embedding(len(stoi), emb_dim)\n",
        "emb.weight\n",
        "emb.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Of0dpDOEmzOw"
      },
      "outputs": [],
      "source": [
        "# Function to visualize the embedding in 2d space\n",
        "\n",
        "# def plot_emb(emb, itos, ax=None):\n",
        "#     if ax is None:\n",
        "#         fig, ax = plt.subplots()\n",
        "#     for i in range(len(itos)):\n",
        "#         x, y = emb.weight[i].detach().cpu().numpy()\n",
        "#         ax.scatter(x, y, color='k')\n",
        "#         ax.text(x + 0.05, y + 0.05, itos[i])\n",
        "#     return ax\n",
        "\n",
        "# plot_emb(emb, itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "KZHYNO8NmzOw"
      },
      "outputs": [],
      "source": [
        "class NextChar(nn.Module):\n",
        "  def __init__(self, block_size, vocab_size, emb_dim, hidden_size):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.lin1 = nn.Linear(block_size * emb_dim, hidden_size)\n",
        "    self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lin3 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.lin4 = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = torch.sin(self.lin1(x))\n",
        "    x = torch.sin(self.lin2(x))\n",
        "    x = torch.sin(self.lin3(x))\n",
        "    x = self.lin4(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKGlcQCUmzOx",
        "outputId": "53954039-4daa-46c1-cdd3-7613947f18b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s P\n",
            ".:Qiae\n"
          ]
        }
      ],
      "source": [
        "# Generate Text from untrained model\n",
        "\n",
        "\n",
        "model = NextChar(block_size, len(stoi), emb_dim, 10).to(device)\n",
        "# model = torch.compile(model)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(4000002)\n",
        "def generate_text(model, itos, stoi, block_size,iptxt=\"\",max_len=10):\n",
        "    context=[]\n",
        "    if len(iptxt)<block_size:\n",
        "      context=[1]*(block_size-len(iptxt))\n",
        "      for char in iptxt:\n",
        "        idx=stoi[char]\n",
        "        context.append(idx)\n",
        "    else:\n",
        "      for i in range(len(iptxt)-block_size,len(iptxt)):\n",
        "          idx=stoi[iptxt[i]]\n",
        "          context.append(idx)\n",
        "    txt = ''\n",
        "    for i in range(max_len):\n",
        "        x = torch.tensor(context).view(1, -1).to(device)\n",
        "        y_pred = model(x)\n",
        "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
        "        ch = itos[ix]\n",
        "        txt += ch\n",
        "        context = context[1:] + [ix]\n",
        "    return txt\n",
        "\n",
        "print(generate_text(model, itos, stoi, block_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM-Fwb8fmzOx",
        "outputId": "d8f37dfa-169d-44f3-ed3a-6d81ce766834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emb.weight torch.Size([62, 8])\n",
            "lin1.weight torch.Size([10, 160])\n",
            "lin1.bias torch.Size([10])\n",
            "lin2.weight torch.Size([10, 10])\n",
            "lin2.bias torch.Size([10])\n",
            "lin3.weight torch.Size([10, 10])\n",
            "lin3.bias torch.Size([10])\n",
            "lin4.weight torch.Size([62, 10])\n",
            "lin4.bias torch.Size([62])\n"
          ]
        }
      ],
      "source": [
        "for param_name, param in model.named_parameters():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcV9pgfmzOx",
        "outputId": "30e21be8-76d3-498c-fcc3-9a4910bbd7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 3.2594690322875977\n",
            "100 2.047478675842285\n",
            "200 2.0254297256469727\n",
            "300 2.013810157775879\n",
            "400 2.016414165496826\n",
            "500 2.022385358810425\n",
            "600 2.0284018516540527\n",
            "700 2.0320067405700684\n",
            "800 2.0277352333068848\n",
            "900 2.026193618774414\n",
            "Model weights saved successfully.\n"
          ]
        }
      ],
      "source": [
        "#code for training\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "import time\n",
        "# Mini-batch training\n",
        "batch_size = 4096\n",
        "print_every = 100\n",
        "elapsed_time = []\n",
        "for epoch in range(1000):\n",
        "    start_time = time.time()\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        x = X[i:i+batch_size]\n",
        "        y = Y[i:i+batch_size]\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    end_time = time.time()\n",
        "    elapsed_time.append(end_time - start_time)\n",
        "    if epoch % print_every == 0:\n",
        "        print(epoch, loss.item())\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), \"model_weights.pth\")\n",
        "print(\"Model weights saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Iwk6XmRPA0",
        "outputId": "83b78fb5-3349-4786-b8cd-e1f7d70885ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "YcTzu_cYmzOx"
      },
      "outputs": [],
      "source": [
        "# Visualize the embedding\n",
        "\n",
        "# plot_emb(model.emb, itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNgoW2cGmzOx",
        "outputId": "12fb720f-371e-4030-b55e-5c219bafd44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dtet, ingfp?\n",
            "\n",
            "Gast stine,\n",
            "Moneepronced pare firchied loxt, bult of ple\n",
            "Lingund sissio srosonget o thy \n"
          ]
        }
      ],
      "source": [
        "#generate text\n",
        "inp='uu'\n",
        "print(generate_text(model, itos, stoi,block_size,inp,100+len(inp)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcH-fjrRhV7",
        "outputId": "6af22e8c-5b2f-4a12-d9eb-2e4db727fda0"
      },
      "outputs": [],
      "source": [
        "# Streamlit UI\n",
        "st.title(\"Next Character Predictor\")\n",
        "\n",
        "input_text = st.text_input(\"Enter your input text:\")\n",
        "k = st.slider(\"Number of characters to predict:\", min_value=1, max_value=20, value=5)\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    if input_text:\n",
        "        predicted_text = generate_text(input_text, model, itos, stoi, block_size, k)\n",
        "        st.write(\"Predicted Text:\", predicted_text)\n",
        "    else:\n",
        "        st.warning(\"Please enter some input text.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
